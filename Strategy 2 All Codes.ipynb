{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0977bd",
   "metadata": {},
   "source": [
    "### Step 1:- It reads an Excel file containing company names and their oldest prices (01-01-2020).\n",
    "It then:\n",
    "1) Takes an investment amount as input (e.g., ₹50,000 per company).\n",
    "\n",
    "2) Generates all possible 4-company combinations from the list.\n",
    "\n",
    "3) For each combination, it:\n",
    "\n",
    "* Calculates how many shares (quantity) can be bought for each company using\n",
    "Quantity = Investment / Oldest Price\n",
    "\n",
    "* Replaces invalid or zero prices with \"NA\".\n",
    "\n",
    "4) Stores each combo as:\n",
    "\n",
    "* Combo → list of 4 company names\n",
    "\n",
    "* Quantity → corresponding share quantities\n",
    "\n",
    "5) Saves the final result to a new Excel file:\n",
    "\n",
    "* 4company_combo_qty.xlsx\n",
    "\n",
    "In simple terms: It creates all possible 4-company portfolios and calculates how many shares you could buy for each company using the oldest price and a fixed investment amount.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c96d4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Investment amount per company (example 50000) : 50000\n",
      "\n",
      "Done! File saved at: C:\\Users\\Swarupa\\Desktop\\Code Details\\4company_combo_qty.xlsx\n"
     ]
    }
   ],
   "source": [
    "#4company_combo_oldest_day_qty\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "input_file = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\50 comp_oldest_price (input file).xlsx\"\n",
    "\n",
    "INVESTMENT = float(input(\"Enter Investment amount per company (example 50000) : \"))\n",
    "\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "company_col = 'Company Name '\n",
    "price_col   = '01-01-2020(oldest price)'\n",
    "\n",
    "df = df[[company_col, price_col]]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for combo in combinations(df.index, 4):\n",
    "    comps = df.loc[list(combo)]\n",
    "    combo_name = \",\".join(comps[company_col])\n",
    "\n",
    "    qty_values = []\n",
    "    for _, r in comps.iterrows():\n",
    "        price = r[price_col]\n",
    "        if price == 0 or pd.isna(price):\n",
    "            qty_values.append(\"NA\")\n",
    "        else:\n",
    "            qty_values.append(f\"{INVESTMENT/price:.2f}\")\n",
    "\n",
    "    qty_text = \",\".join(qty_values)   # only quantities\n",
    "\n",
    "    rows.append([combo_name, qty_text])\n",
    "\n",
    "out_df = pd.DataFrame(rows, columns=['Combo','Quantity'])\n",
    "\n",
    "output_file = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\4company_combo_qty.xlsx\"\n",
    "out_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"\\nDone! File saved at:\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7513840",
   "metadata": {},
   "source": [
    "### Step 2:-  It calculates the total price for each 4-company combo on each date based on company prices and quantities. It does the following:\n",
    "1) Loads price data for 50 companies over different dates and company combos with their quantities.\n",
    "\n",
    "2) Matches the company names in the combos with their corresponding prices for each date.\n",
    "\n",
    "3) Calculates total prices for each combo by multiplying the price of each company by its quantity for that date.\n",
    "\n",
    "4) Saves the results in a CSV file with columns: Date, Combo, Price per Combo, and Total Price.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f49c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swarupa\\AppData\\Local\\Temp\\4\\ipykernel_8636\\2794523497.py:53: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  combo_indices = df_combo[['C1','C2','C3','C4']].applymap(lambda x: col_index.get(x, -1)).values\n",
      "Processing: 100%|█████████████████████████████████████████████████| 322650300/322650300 [1:58:36<00:00, 45335.90rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FAST output generated at:\n",
      "C:\\Users\\Swarupa\\Desktop\\Code Details\\output_result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4Combo_TotalPrices\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# ----------------------------------------\n",
    "# Input paths\n",
    "# ----------------------------------------\n",
    "file_prices = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\50 comp data (input file).xlsx\"\n",
    "file_combos = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\4company_combo_oldest_day_qty.xlsx\"\n",
    "output_file = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_result.csv\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load price data\n",
    "# ----------------------------------------\n",
    "df_price = pd.read_excel(file_prices)\n",
    "date_col = df_price.columns[0]\n",
    "company_cols = df_price.columns[1:]\n",
    "\n",
    "dates = df_price[date_col].values\n",
    "price_matrix = df_price[company_cols].values   \n",
    "\n",
    "# ----------------------------------------\n",
    "# Load combos\n",
    "# ----------------------------------------\n",
    "df_combo = pd.read_excel(file_combos)\n",
    "df_combo.columns = df_combo.columns.str.strip()\n",
    "\n",
    "# Split companies\n",
    "df_combo[['C1','C2','C3','C4']] = df_combo['Combo'].str.split(',', expand=True)\n",
    "\n",
    "# Split quantities \n",
    "def split_qty(qty):\n",
    "    out = []\n",
    "    for x in str(qty).split(\",\"):\n",
    "        x = x.strip()\n",
    "        try:\n",
    "            out.append(float(x))\n",
    "        except:\n",
    "            out.append(0.0)\n",
    "    while len(out) < 4:\n",
    "        out.append(0.0)\n",
    "    return out[:4]\n",
    "\n",
    "df_combo[['Q1','Q2','Q3','Q4']] = df_combo['Quantity'].apply(split_qty).tolist()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Prepare index lookup for companies\n",
    "# ----------------------------------------\n",
    "col_index = {col: i for i, col in enumerate(company_cols)}\n",
    "\n",
    "# Convert combos to index rows\n",
    "combo_indices = df_combo[['C1','C2','C3','C4']].applymap(lambda x: col_index.get(x, -1)).values\n",
    "qty_matrix = df_combo[['Q1','Q2','Q3','Q4']].values\n",
    "\n",
    "num_dates = len(dates)\n",
    "num_combos = len(df_combo)\n",
    "\n",
    "# ----------------------------------------\n",
    "# CSV Header\n",
    "# ----------------------------------------\n",
    "with open(output_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"DATE\", \"Combo\", \"Price_Combo\", \"TotalPrice\"])\n",
    "\n",
    "# ----------------------------------------\n",
    "# PROCESS WITH PROGRESS BAR\n",
    "# ----------------------------------------\n",
    "total_ops = num_dates * num_combos\n",
    "\n",
    "with open(output_file, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    pbar = tqdm(total=total_ops, desc=\"Processing\", unit=\"rows\")\n",
    "\n",
    "    for d_idx, date_value in enumerate(dates):\n",
    "\n",
    "        # Extract all prices for this date \n",
    "        price_row = price_matrix[d_idx]          \n",
    "\n",
    "        # Get 4 prices for all combos\n",
    "        p = price_row[combo_indices]             \n",
    "\n",
    "        # Compute total price\n",
    "        total_price = np.sum(p * qty_matrix, axis=1)\n",
    "\n",
    "        # Write each combo for this date\n",
    "        for i in range(num_combos):\n",
    "            writer.writerow([\n",
    "                date_value,\n",
    "                df_combo[\"Combo\"].iloc[i],\n",
    "                list(p[i]),    \n",
    "                total_price[i]\n",
    "            ])\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "print(\"\\nFAST output generated at:\")\n",
    "print(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d90895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE                                         Combo  \\\n",
      "0  2020-01-01  Adani Port,Apollo Hosp,Asian Paint,Axis bank   \n",
      "1  2020-01-02  Adani Port,Apollo Hosp,Asian Paint,Axis bank   \n",
      "2  2020-01-03  Adani Port,Apollo Hosp,Asian Paint,Axis bank   \n",
      "3  2020-01-06  Adani Port,Apollo Hosp,Asian Paint,Axis bank   \n",
      "4  2020-01-07  Adani Port,Apollo Hosp,Asian Paint,Axis bank   \n",
      "\n",
      "                          Price_Combo   TotalPrice  \n",
      "0    [377.65, 1426.35, 1793.2, 748.7]  199987.0295  \n",
      "1  [383.15, 1494.65, 1790.65, 756.95]  203588.9855  \n",
      "2     [382.5, 1486.1, 1751.4, 742.95]  201174.0380  \n",
      "3    [380.2, 1462.5, 1707.15, 723.25]  197493.0820  \n",
      "4     [384.8, 1478.7, 1724.4, 725.75]  199317.8120  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\4company_combo_total_price.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(df.head())          # show first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54c722",
   "metadata": {},
   "source": [
    "### Step 3:- It processes a CSV file of 4-company combos and calculates:\n",
    "1) EURINR Ratio: For each combo on each date, it computes the ratio of TotalPrice to the EURINR exchange rate.\n",
    "\n",
    "2) 50-Day Moving Average (DMA): It calculates a rolling 50-day average of the EURINR Ratio for each combo, keeping a continuous history.\n",
    "\n",
    "3) It processes the data in chunks to handle large files efficiently and appends the results (Date, Combo, EURINR Ratio, 50DMA) to a new CSV file.\n",
    "\n",
    "The output is saved in a CSV file with the calculated EURINR Ratio and 50DMA for each combo across the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec13d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 1643rows [11:47,  2.32rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DONE — Output saved to:\n",
      "C:\\Users\\Swarupa\\Desktop\\Code Details\\output_with_EURINR_50DMA_EURINR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4Company_EURINR_Ratio_50DMA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# INPUT FILES\n",
    "# ---------------------------------------------------\n",
    "file_csv = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_result.csv\"\n",
    "file_eurinr = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\EURINR Values(input file).xlsx\"\n",
    "final_output = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_with_EURINR_50DMA_EURINR.csv\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# LOAD EURINR VALUES\n",
    "# ---------------------------------------------------\n",
    "eur = pd.read_excel(file_eurinr)\n",
    "eur[\"DATE\"] = pd.to_datetime(eur[\"DATE\"])\n",
    "\n",
    "# Convert for fast lookup\n",
    "eur_dict = dict(zip(eur[\"DATE\"], eur[\"EURINR\"]))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# PARAMETERS\n",
    "# ---------------------------------------------------\n",
    "chunksize = 50000\n",
    "state = {}             \n",
    "header_written = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# PROCESS CSV IN STREAMING MODE\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nProcessing file...\\n\")\n",
    "\n",
    "for chunk in tqdm(pd.read_csv(file_csv, chunksize=chunksize, parse_dates=[\"DATE\"]),\n",
    "                  desc=\"Processing\", unit=\"rows\"):\n",
    "\n",
    "    # Sort chunk\n",
    "    chunk.sort_values([\"Combo\", \"DATE\"], inplace=True)\n",
    "\n",
    "    # Correct EURINR ratio\n",
    "    chunk[\"EURINR\"] = chunk[\"DATE\"].map(eur_dict)\n",
    "    chunk[\"EURINR_Ratio\"] = chunk[\"TotalPrice\"] / chunk[\"EURINR\"]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 50-DAY DMA CALCULATION\n",
    "    # ------------------------------------------------\n",
    "    DMA_list = []\n",
    "\n",
    "    for combo, subdf in chunk.groupby(\"Combo\"):\n",
    "        past = state.get(combo, [])\n",
    "\n",
    "        series = np.concatenate([past, subdf[\"EURINR_Ratio\"].to_numpy()])\n",
    "\n",
    "        roll = (\n",
    "            pd.Series(series)\n",
    "            .rolling(window=50, min_periods=50)\n",
    "            .mean()\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        DMA_current = roll[len(past):]\n",
    "\n",
    "        DMA_list.append(pd.Series(DMA_current, index=subdf.index))\n",
    "\n",
    "        # keep last 49 values for continuity\n",
    "        state[combo] = series[-49:].tolist()\n",
    "\n",
    "    # merge results\n",
    "    chunk[\"50DMA_EURINR\"] = pd.concat(DMA_list).sort_index()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # KEEP ONLY REQUIRED COLUMNS\n",
    "    # ------------------------------------------------\n",
    "    final_chunk = chunk[[\"DATE\", \"Combo\", \"EURINR_Ratio\", \"50DMA_EURINR\"]]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # SAVE OUTPUT\n",
    "    # ------------------------------------------------\n",
    "    final_chunk.to_csv(\n",
    "        final_output,\n",
    "        mode=\"a\",\n",
    "        index=False,\n",
    "        header=not header_written\n",
    "    )\n",
    "    header_written = True\n",
    "\n",
    "print(\"\\n DONE — Output saved to:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5315f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: (10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Combo</th>\n",
       "      <th>EURINR_Ratio</th>\n",
       "      <th>50DMA_EURINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Axis bank</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Axis bank</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Axis bank</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE                                         Combo  EURINR_Ratio  \\\n",
       "0  2020-01-01  Adani Port,Apollo Hosp,Asian Paint,Axis bank           inf   \n",
       "1  2020-01-02  Adani Port,Apollo Hosp,Asian Paint,Axis bank           inf   \n",
       "2  2020-01-03  Adani Port,Apollo Hosp,Asian Paint,Axis bank           inf   \n",
       "\n",
       "   50DMA_EURINR  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2: (10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Combo</th>\n",
       "      <th>EURINR_Ratio</th>\n",
       "      <th>50DMA_EURINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Coal india</td>\n",
       "      <td>2407.323307</td>\n",
       "      <td>2211.843197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Coal india</td>\n",
       "      <td>2407.600137</td>\n",
       "      <td>2217.930659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,Coal india</td>\n",
       "      <td>2423.130590</td>\n",
       "      <td>2224.679052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE                                          Combo  \\\n",
       "10000  2020-10-08  Adani Port,Apollo Hosp,Asian Paint,Coal india   \n",
       "10001  2020-10-09  Adani Port,Apollo Hosp,Asian Paint,Coal india   \n",
       "10002  2020-10-12  Adani Port,Apollo Hosp,Asian Paint,Coal india   \n",
       "\n",
       "       EURINR_Ratio  50DMA_EURINR  \n",
       "10000   2407.323307   2211.843197  \n",
       "10001   2407.600137   2217.930659  \n",
       "10002   2423.130590   2224.679052  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3: (10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Combo</th>\n",
       "      <th>EURINR_Ratio</th>\n",
       "      <th>50DMA_EURINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,HUL</td>\n",
       "      <td>4176.824730</td>\n",
       "      <td>4083.451442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,HUL</td>\n",
       "      <td>4231.351160</td>\n",
       "      <td>4086.027698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Adani Port,Apollo Hosp,Asian Paint,HUL</td>\n",
       "      <td>4266.221725</td>\n",
       "      <td>4089.844562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE                                   Combo  EURINR_Ratio  \\\n",
       "20000  2021-07-19  Adani Port,Apollo Hosp,Asian Paint,HUL   4176.824730   \n",
       "20001  2021-07-20  Adani Port,Apollo Hosp,Asian Paint,HUL   4231.351160   \n",
       "20002  2021-07-22  Adani Port,Apollo Hosp,Asian Paint,HUL   4266.221725   \n",
       "\n",
       "       50DMA_EURINR  \n",
       "20000   4083.451442  \n",
       "20001   4086.027698  \n",
       "20002   4089.844562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_with_EURINR_50DMA_EURINR.csv\"\n",
    "\n",
    "chunksize = 10000  # read 10k rows at a time\n",
    "reader = pd.read_csv(file_path, chunksize=chunksize)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    print(f\"Chunk {i+1}: {chunk.shape}\")\n",
    "    display(chunk.head(3))  # show first 3 rows of each chunk\n",
    "    if i == 2:  # stop after 3 chunks\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc9e2e",
   "metadata": {},
   "source": [
    "### Step 4:- It checks which 4-company combos satisfy the condition:  EURINR_Ratio > 50DMA_EURINR for all the latest 3 selected dates.\n",
    "Steps done by the code:\n",
    "\n",
    "1) Loads the CSV that contains each combo’s EURINR Ratio and 50-day moving average.\n",
    "\n",
    "2) Filters the data only for the latest 3 dates you specified.\n",
    "\n",
    "3) For each combo:\n",
    "\n",
    "* Ensures all 3 dates exist.\n",
    "\n",
    "* Checks if EURINR_Ratio > 50DMA_EURINR on all 3 dates.\n",
    "\n",
    "4) For combos that pass, it creates a pivoted row with the values arranged horizontally.\n",
    "\n",
    "5) Saves the final shortlisted combos to an Excel file.\n",
    "\n",
    "In short:\n",
    "It finds all combos where EURINR_Ratio is greater than 50DMA_EURINR on all selected latest 3 days and exports the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bf7d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Filtering latest 3 dates...\n",
      "Applying condition EURINR_Ratio > 50DMA_EURINR...\n",
      "Saving optimized output...\n",
      "\n",
      " DONE! file created:\n",
      "D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_TotalPrice_GT_50DMA_EURINR.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Latest_3days_EURINR_Ratio>50DMA_EURINR\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ----------- USER INPUTS -----------\n",
    "input_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\output_with_EURINR_50DMA_EURINR.csv\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_TotalPrice_GT_50DMA_EURINR.xlsx\"\n",
    "\n",
    "dates_to_check = [\"2025-08-19\", \"2025-08-18\", \"2025-08-14\"]\n",
    "\n",
    "\n",
    "print(\"Loading file...\")\n",
    "df = pd.read_csv(input_file, usecols=[\"DATE\", \"Combo\", \"EURINR_Ratio\", \"50DMA_EURINR\"])\n",
    "\n",
    "# Ensure DATE is string\n",
    "df[\"DATE\"] = df[\"DATE\"].astype(str)\n",
    "\n",
    "print(\"Filtering latest 3 dates...\")\n",
    "df = df[df[\"DATE\"].isin(dates_to_check)]\n",
    "\n",
    "print(\"Applying condition EURINR_Ratio > 50DMA_EURINR...\")\n",
    "\n",
    "# Keep only rows satisfying condition\n",
    "df_valid = df[df[\"EURINR_Ratio\"] > df[\"50DMA_EURINR\"]]\n",
    "\n",
    "# Count valid rows per combo\n",
    "combo_counts = df_valid.groupby(\"Combo\")[\"DATE\"].nunique()\n",
    "\n",
    "# Only keep combos present in ALL 3 dates\n",
    "valid_combos = combo_counts[combo_counts == 3].index\n",
    "\n",
    "final_df = df_valid[df_valid[\"Combo\"].isin(valid_combos)]\n",
    "\n",
    "# Sort output: Combo wise + latest date first\n",
    "final_df = final_df.sort_values(by=[\"Combo\", \"DATE\"], ascending=[True, False])\n",
    "\n",
    "print(\"Saving optimized output...\")\n",
    "final_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"\\n DONE! file created:\")\n",
    "print(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560d2bc",
   "metadata": {},
   "source": [
    "### Step 5:-  It processes a CSV file of 4-company combos and calculates:\n",
    "1) NIFTY Ratio: For each combo on each date, it computes the ratio of TotalPrice to the NIFTY  exchange rate.\n",
    "\n",
    "2) 50-Day Moving Average (DMA): It calculates a rolling 50-day average of the NIFTY Ratio for each combo, keeping a continuous history.\n",
    "\n",
    "3) It processes the data in chunks to handle large files efficiently and appends the results (Date, Combo, NIFTY Ratio, 50DMA) to a new CSV file.\n",
    "\n",
    "The output is saved in a CSV file with the calculated NIFTY Ratio and 50DMA for each combo across the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508b4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 1643rows [12:21,  2.22rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DONE — Output saved to:\n",
      "C:\\Users\\Swarupa\\Desktop\\Code Details\\output_with_NIFTY_50DMA_Nifty.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4Company_NIFTY_Ratio_50DMA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# INPUT FILES\n",
    "# ---------------------------------------------------\n",
    "file_csv = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_result.csv\"\n",
    "file_nifty = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\Nifty_Index_values(input file).xlsx\"\n",
    "final_output = r\"C:\\Users\\Swarupa\\Desktop\\Code Details\\output_with_NIFTY_50DMA_Nifty.csv\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# LOAD NIFTY VALUES\n",
    "# ---------------------------------------------------\n",
    "nifty = pd.read_excel(file_nifty)\n",
    "nifty[\"DATE\"] = pd.to_datetime(nifty[\"DATE\"])\n",
    "\n",
    "# Convert for fast lookup\n",
    "nifty_dict = dict(zip(nifty[\"DATE\"], nifty[\"NIFTY\"]))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# PARAMETERS\n",
    "# ---------------------------------------------------\n",
    "chunksize = 50000\n",
    "state = {}             \n",
    "header_written = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# PROCESS CSV IN STREAMING MODE\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nProcessing file...\\n\")\n",
    "\n",
    "for chunk in tqdm(pd.read_csv(file_csv, chunksize=chunksize, parse_dates=[\"DATE\"]),\n",
    "                  desc=\"Processing\", unit=\"rows\"):\n",
    "\n",
    "    # Sort chunk\n",
    "    chunk.sort_values([\"Combo\", \"DATE\"], inplace=True)\n",
    "\n",
    "    # Correct NIFTY ratio\n",
    "    chunk[\"NIFTY\"] = chunk[\"DATE\"].map(nifty_dict)\n",
    "    chunk[\"NIFTY_Ratio\"] = chunk[\"TotalPrice\"] / chunk[\"NIFTY\"]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 50-DAY DMA CALCULATION (for NIFTY_Ratio)\n",
    "    # ------------------------------------------------\n",
    "    DMA_list = []\n",
    "\n",
    "    for combo, subdf in chunk.groupby(\"Combo\"):\n",
    "        past = state.get(combo, [])\n",
    "\n",
    "        series = np.concatenate([past, subdf[\"NIFTY_Ratio\"].to_numpy()])\n",
    "\n",
    "        roll = (\n",
    "            pd.Series(series)\n",
    "            .rolling(window=50, min_periods=50)\n",
    "            .mean()\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        DMA_current = roll[len(past):]\n",
    "\n",
    "        DMA_list.append(pd.Series(DMA_current, index=subdf.index))\n",
    "\n",
    "        # keep last 49 values for continuity\n",
    "        state[combo] = series[-49:].tolist()\n",
    "\n",
    "    # merge results\n",
    "    chunk[\"50DMA_NIFTY\"] = pd.concat(DMA_list).sort_index()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # KEEP ONLY REQUIRED COLUMNS\n",
    "    # ------------------------------------------------\n",
    "    final_chunk = chunk[[\"DATE\", \"Combo\", \"NIFTY_Ratio\", \"50DMA_NIFTY\"]]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # SAVE OUTPUT\n",
    "    # ------------------------------------------------\n",
    "    final_chunk.to_csv(\n",
    "        final_output,\n",
    "        mode=\"a\",\n",
    "        index=False,\n",
    "        header=not header_written\n",
    "    )\n",
    "    header_written = True\n",
    "\n",
    "print(\"\\n DONE — Output saved to:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb969e5",
   "metadata": {},
   "source": [
    "### Step 6:- It checks which 4-company combos satisfy the condition: NIFTY_Ratio > 50DMA_NIFTY for all the latest 3 selected dates.\n",
    "Steps done by the code:\n",
    "\n",
    "1) Loads the CSV that contains each combo’s NIFTY Ratio and 50-day moving average.\n",
    "\n",
    "2) Filters the data only for the latest 3 dates you specified.\n",
    "\n",
    "3) For each combo:\n",
    "\n",
    "* Ensures all 3 dates exist.\n",
    "\n",
    "* Checks if NIFTY_Ratio > 50DMA_NIFTY on all 3 dates.\n",
    "\n",
    "4) For combos that pass, it creates a pivoted row with the values arranged horizontally.\n",
    "\n",
    "5) Saves the final shortlisted combos to an Excel file.\n",
    "\n",
    "In short:\n",
    "It finds all combos where NIFTY_Ratio is greater than 50DMA_NIFTY on all selected latest 3 days and exports the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b7434a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Filtering latest 3 dates...\n",
      "Applying condition NIFTY_Ratio > 50DMA_NIFTY...\n",
      "Saving optimized output...\n",
      "\n",
      " DONE! NIFTY file created:\n",
      "D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_NIFTY_Ratio_GT_50DMA_NIFTY.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Latest_3days_NIFTY_Ratio>50DMA_NIFTY\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ----------- USER INPUTS -----------\n",
    "input_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\output_with_NIFTY_50DMA_Nifty.csv\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_NIFTY_Ratio_GT_50DMA_NIFTY.xlsx\"\n",
    "\n",
    "dates_to_check = [\"2025-08-19\", \"2025-08-18\", \"2025-08-14\"]\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"Loading file...\")\n",
    "df = pd.read_csv(input_file, usecols=[\"DATE\", \"Combo\", \"NIFTY_Ratio\", \"50DMA_NIFTY\"])\n",
    "\n",
    "# Ensure DATE is string\n",
    "df[\"DATE\"] = df[\"DATE\"].astype(str)\n",
    "\n",
    "print(\"Filtering latest 3 dates...\")\n",
    "df = df[df[\"DATE\"].isin(dates_to_check)]\n",
    "\n",
    "print(\"Applying condition NIFTY_Ratio > 50DMA_NIFTY...\")\n",
    "\n",
    "# Keep only rows satisfying condition\n",
    "df_valid = df[df[\"NIFTY_Ratio\"] > df[\"50DMA_NIFTY\"]]\n",
    "\n",
    "# Count valid rows per combo\n",
    "combo_counts = df_valid.groupby(\"Combo\")[\"DATE\"].nunique()\n",
    "\n",
    "# Only keep combos present in ALL 3 dates\n",
    "valid_combos = combo_counts[combo_counts == 3].index\n",
    "\n",
    "final_df = df_valid[df_valid[\"Combo\"].isin(valid_combos)]\n",
    "\n",
    "# Sort neatly: combo-wise + latest date first\n",
    "final_df = final_df.sort_values(by=[\"Combo\", \"DATE\"], ascending=[True, False])\n",
    "\n",
    "print(\"Saving optimized output...\")\n",
    "final_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"\\n DONE! NIFTY file created:\")\n",
    "print(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9d633",
   "metadata": {},
   "source": [
    "### Step 7:- It finds common 4-company combinations that appear in both:\n",
    "\n",
    "\n",
    "* The EURINR filtered file\n",
    "\n",
    "\n",
    "* The NIFTY filtered file\n",
    "\n",
    "\n",
    "Steps done:\n",
    "\n",
    "\n",
    "1) Loads both Excel files containing combos that satisfy their respective conditions.\n",
    "\n",
    "\n",
    "2) Removes any duplicate combo rows.\n",
    "\n",
    "\n",
    "3) Performs an INNER JOIN on the “Combo” column → keeping only combos present in both datasets.\n",
    "\n",
    "\n",
    "4) Saves the matched common combos to a new Excel file.\n",
    "\n",
    "\n",
    "In short:\n",
    "It identifies and exports the combos that pass BOTH EURINR and NIFTY conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91e5c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EURINR file...\n",
      "Loading NIFTY file...\n",
      "Finding common combos...\n",
      "Saving output...\n",
      "\n",
      " DONE! Common combos with EURINR + NIFTY values saved at:\n",
      "D:\\Trading Stratergies\\Stratergy 2 All Codes\\Common_Combinations_EURINR_NIFTY.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Common_Combinations_EURINR_NIFTY\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- USER INPUTS ----------------\n",
    "eurinr_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_TotalPrice_GT_50DMA_EURINR.xlsx\"\n",
    "nifty_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_3days_NIFTY_Ratio_GT_50DMA_NIFTY.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Common_Combinations_EURINR_NIFTY.xlsx\"\n",
    "\n",
    "\n",
    "print(\"Loading EURINR file...\")\n",
    "df_eur = pd.read_excel(eurinr_file, engine=\"openpyxl\")\n",
    "\n",
    "print(\"Loading NIFTY file...\")\n",
    "df_nifty = pd.read_excel(nifty_file, engine=\"openpyxl\")\n",
    "\n",
    "# Ensure DATE is datetime\n",
    "df_eur[\"DATE\"] = pd.to_datetime(df_eur[\"DATE\"])\n",
    "df_nifty[\"DATE\"] = pd.to_datetime(df_nifty[\"DATE\"])\n",
    "\n",
    "# Drop duplicate combos if any\n",
    "df_eur = df_eur.drop_duplicates(subset=[\"Combo\", \"DATE\"])\n",
    "df_nifty = df_nifty.drop_duplicates(subset=[\"Combo\", \"DATE\"])\n",
    "\n",
    "print(\"Finding common combos...\")\n",
    "\n",
    "# Merge on Combo AND DATE to get side-by-side values\n",
    "merged_df = pd.merge(\n",
    "    df_eur, \n",
    "    df_nifty, \n",
    "    on=[\"Combo\", \"DATE\"], \n",
    "    how=\"inner\", \n",
    "    suffixes=(\"_EURINR\", \"_NIFTY\")\n",
    ")\n",
    "\n",
    "# Optional: sort by Combo & latest date first\n",
    "merged_df = merged_df.sort_values(by=[\"Combo\", \"DATE\"], ascending=[True, False])\n",
    "\n",
    "# Convert DATE back to string for Excel readability\n",
    "merged_df[\"DATE\"] = merged_df[\"DATE\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(\"Saving output...\")\n",
    "merged_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"\\n DONE! Common combos with EURINR + NIFTY values saved at:\")\n",
    "print(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb718a1f",
   "metadata": {},
   "source": [
    "### Step 9:- This code:\n",
    "\n",
    "1) Loads the Excel file that contains all combinations with their EURINR & NIFTY Ratios and 50DMA values for multiple dates.\n",
    "\n",
    "2) Extracts all dates from the column names automatically (e.g., 2025-08-19, 2025-08-18, etc.).\n",
    "\n",
    "3) For each row (each combo) it checks every date to see if:\n",
    "\n",
    "* EURINR_Ratio ≤ 1.03 × 50DMA_EURINR\n",
    "\n",
    "* NIFTY_Ratio ≤ 1.03 × 50DMA_NIFTY\n",
    "\n",
    "4) If the row satisfies the condition for at least one date, that row is kept.\n",
    "\n",
    "5) A progress bar shows checking status.\n",
    "\n",
    "6) Finally, all matching rows are saved into a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb945ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date detected: 2025-08-19\n",
      "\n",
      "Filtering Completed\n",
      "Total rows for latest date : 11938\n",
      "Rows kept after filter    : 1942\n",
      "Output saved to: D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_day_Ratio_should_not_be_GT_1.03_times_50DMA.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Ratio<=1.03*50DMA(latest_day)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- INPUT / OUTPUT ----------------\n",
    "input_file  = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Common_Combinations_EURINR_NIFTY.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_day_Ratio_should_not_be_GT_1.03_times_50DMA.xlsx\"\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(input_file, engine=\"openpyxl\")\n",
    "\n",
    "# Ensure DATE is datetime\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "\n",
    "# Detect latest date automatically\n",
    "latest_date = df[\"DATE\"].max()\n",
    "print(\"Latest date detected:\", latest_date.date())\n",
    "\n",
    "# Filter rows for latest date\n",
    "df_latest = df[df[\"DATE\"] == latest_date]\n",
    "\n",
    "# Apply vectorized condition\n",
    "condition = (\n",
    "    (df_latest[\"EURINR_Ratio\"] <= 1.03 * df_latest[\"50DMA_EURINR\"]) &\n",
    "    (df_latest[\"NIFTY_Ratio\"]  <= 1.03 * df_latest[\"50DMA_NIFTY\"])\n",
    ")\n",
    "\n",
    "filtered_df = df_latest.loc[condition].reset_index(drop=True)\n",
    "\n",
    "# Save output\n",
    "filtered_df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"\\nFiltering Completed\")\n",
    "print(\"Total rows for latest date :\", len(df_latest))\n",
    "print(\"Rows kept after filter    :\", len(filtered_df))\n",
    "print(\"Output saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e9d9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest average ratio combos saved to: D:\\Trading Stratergies\\Stratergy 2 All Codes\\Top10_Highest_Average_Ratio.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Top10_Highest_Average_Ratio\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- INPUT / OUTPUT ----------------\n",
    "input_file  = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_day_Ratio_should_not_be_GT_1.03_times_50DMA.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Top10_Highest_Average_Ratio.xlsx\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(input_file, engine=\"openpyxl\")\n",
    "\n",
    "# Compute average ratio per row (EURINR + NIFTY)\n",
    "df[\"Avg_Ratio\"] = (df[\"EURINR_Ratio\"] + df[\"NIFTY_Ratio\"]) / 2\n",
    "\n",
    "# Group by Combo and calculate mean of Avg_Ratio\n",
    "combo_avg = df.groupby(\"Combo\")[\"Avg_Ratio\"].mean().reset_index()\n",
    "\n",
    "# Sort descending to get highest average ratios\n",
    "combo_avg = combo_avg.sort_values(by=\"Avg_Ratio\", ascending=False)\n",
    "\n",
    "# Keep Top 10 combos\n",
    "top10_combos = combo_avg.head(10)\n",
    "\n",
    "# Optional: merge with original data to get all details for these combos\n",
    "top10_details = df[df[\"Combo\"].isin(top10_combos[\"Combo\"])].reset_index(drop=True)\n",
    "\n",
    "# Save to Excel\n",
    "top10_details.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"Top 10 highest average ratio combos saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada60bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swarupa\\AppData\\Local\\Temp\\3\\ipykernel_8420\\20978567.py:21: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = df.pct_change().dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stocks: 50\n",
      "Total 4-stock combinations: 230300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating correlations: 100%|██████████████████████████████████████████████| 230300/230300 [02:58<00:00, 1289.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DONE\n",
      " The TOP row in Excel is your LEAST CORRELATED 4-stock portfolio\n"
     ]
    }
   ],
   "source": [
    "#Average_Realized_Correlation(4Stock_Combinations_Correlation)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= USER INPUT =================\n",
    "input_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\50 comp data (input file).xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\4Stock_Combinations_Correlation.xlsx\"\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Convert DATE column\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Set DATE as index\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = df.pct_change().dropna()\n",
    "\n",
    "stocks = returns.columns.tolist()\n",
    "print(f\"Total Stocks: {len(stocks)}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Generate all 4-stock combinations\n",
    "combinations = list(itertools.combinations(stocks, 4))\n",
    "print(f\"Total 4-stock combinations: {len(combinations)}\")\n",
    "\n",
    "for combo in tqdm(combinations, desc=\"Calculating correlations\"):\n",
    "\n",
    "    data = returns[list(combo)]\n",
    "    corr_matrix = data.corr()\n",
    "\n",
    "    # All 6 pairwise correlations\n",
    "    pairs = list(itertools.combinations(combo, 2))\n",
    "    pair_corrs = [corr_matrix.loc[a, b] for a, b in pairs]\n",
    "\n",
    "    #  YOUR EXACT FORMULA\n",
    "    avg_realized_corr = (0.25 * sum(pair_corrs)) / 1.5\n",
    "\n",
    "    results.append({\n",
    "        \"Combo\": \", \".join(combo),\n",
    "        \"Average_Realized_Correlation\": avg_realized_corr\n",
    "    })\n",
    "\n",
    "# Create result dataframe\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Rank by least correlation\n",
    "result_df = result_df.sort_values(by=\"Average_Realized_Correlation\")\n",
    "\n",
    "# Save output\n",
    "result_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\" DONE\")\n",
    "print(\" The TOP row in Excel is your LEAST CORRELATED 4-stock portfolio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "176e458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Normalizing Combo format...\n",
      "Merging datasets...\n",
      "Saving output...\n",
      " FIXED: Correlation values correctly applied.\n"
     ]
    }
   ],
   "source": [
    "#Average_Correlation_EURINR_NIFTY\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- FILE PATHS ----------------\n",
    "file_corr = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\4Stock_Combinations_Correlation.xlsx\"    \n",
    "file_data = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Latest_day_Ratio_should_not_be_GT_1.03_times_50DMA.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Average_Correlation_EURINR_NIFTY.xlsx\"\n",
    "\n",
    "\n",
    "def normalize_combo(combo):\n",
    "    if pd.isna(combo):\n",
    "        return combo\n",
    "    stocks = [s.strip() for s in combo.split(\",\")]\n",
    "    stocks_sorted = sorted(stocks)\n",
    "    return \", \".join(stocks_sorted)\n",
    "\n",
    "\n",
    "print(\"Loading files...\")\n",
    "df_corr = pd.read_excel(file_corr)\n",
    "df_data = pd.read_excel(file_data)\n",
    "\n",
    "# Normalize combo column in both files\n",
    "print(\"Normalizing Combo format...\")\n",
    "df_corr[\"Combo_Normalized\"] = df_corr[\"Combo\"].apply(normalize_combo)\n",
    "df_data[\"Combo_Normalized\"] = df_data[\"Combo\"].apply(normalize_combo)\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "final_df = df_data.merge(\n",
    "    df_corr[[\"Combo_Normalized\", \"Average_Realized_Correlation\"]],\n",
    "    on=\"Combo_Normalized\",\n",
    "    how=\"left\"   # keeps all second file rows\n",
    ")\n",
    "\n",
    "# Optional: Drop rows where correlation not found\n",
    "final_df = final_df.dropna(subset=[\"Average_Realized_Correlation\"])\n",
    "\n",
    "# Remove helper column\n",
    "final_df.drop(columns=[\"Combo_Normalized\"], inplace=True)\n",
    "\n",
    "print(\"Saving output...\")\n",
    "final_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\" FIXED: Correlation values correctly applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d6a5b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged data file...\n",
      "Sorting by lowest Average_Realized_Correlation...\n",
      "Saving Top 10 lowest correlation combinations...\n",
      " Done! Top 10 Lowest Correlation file created.\n"
     ]
    }
   ],
   "source": [
    "#Top10_Lowest_Correlation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------- USER FILE PATHS --------\n",
    "input_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Average_Correlation_EURINR_NIFTY.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Top10_Lowest_Correlation.xlsx\"\n",
    "\n",
    "print(\"Loading merged data file...\")\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "print(\"Sorting by lowest Average_Realized_Correlation...\")\n",
    "\n",
    "# Sort ascending = lowest correlation first\n",
    "df_sorted = df.sort_values(by=\"Average_Realized_Correlation\", ascending=True)\n",
    "\n",
    "# Select top 10 lowest\n",
    "top10_lowest = df_sorted.head(10)\n",
    "\n",
    "print(\"Saving Top 10 lowest correlation combinations...\")\n",
    "top10_lowest.to_excel(output_file, index=False)\n",
    "\n",
    "print(\" Done! Top 10 Lowest Correlation file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06b4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Expanding Beta: 100%|█████████████████████████████████████████████████████| 53/53 [00:00<00:00, 534.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Beta calculated for each stock and each date using all available data.\n",
      " Output saved to: D:\\Trading Stratergies\\Stratergy 2 All Codes\\expanding_beta_all_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Calculate beta for all data \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- FILE PATHS ----------\n",
    "file_path = r\"D:\\Trading Stratergies\\ndpl\\50 comp data.xlsx\"\n",
    "output_path = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\expanding_beta_all_data.xlsx\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(\"DATE\").reset_index(drop=True)\n",
    "\n",
    "# Market returns\n",
    "market_ret = df[\"Nifty Index\"].pct_change()\n",
    "\n",
    "# Columns to exclude\n",
    "exclude = [\"DATE\", \"EURINR\", \"Nifty Index\"]\n",
    "\n",
    "# Output dataframe\n",
    "beta_result = pd.DataFrame()\n",
    "beta_result[\"DATE\"] = df[\"DATE\"]\n",
    "\n",
    "# Calculate expanding beta for each stock\n",
    "for col in tqdm(df.columns, desc=\"Calculating Expanding Beta\"):\n",
    "    if col not in exclude:\n",
    "\n",
    "        stock_ret = df[col].pct_change()\n",
    "\n",
    "        temp = pd.DataFrame({\n",
    "            \"Stock\": stock_ret,\n",
    "            \"Market\": market_ret\n",
    "        })\n",
    "\n",
    "        # Expanding beta = uses ALL data till that date\n",
    "        beta_series = (\n",
    "            temp[\"Stock\"].expanding().cov(temp[\"Market\"]) /\n",
    "            temp[\"Market\"].expanding().var()\n",
    "        )\n",
    "\n",
    "        beta_result[col + \"_Beta\"] = beta_series\n",
    "\n",
    "# Save result\n",
    "beta_result.to_excel(output_path, index=False)\n",
    "\n",
    "print(\" Beta calculated for each stock and each date using all available data.\")\n",
    "print(\" Output saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0c8aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total Stocks: 50\n",
      "Total 4-stock combinations: 230300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████████████████████████████████████████████████████████| 1401/1401 [31:37<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created successfully!\n",
      "File saved at: D:\\Trading Stratergies\\Stratergy 2 All Codes\\beta_total.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#4_company_beta_total\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# -------- FILE PATHS --------\n",
    "beta_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\expanding_beta_all_data.xlsx\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\beta_total.csv\"\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel(beta_file)\n",
    "\n",
    "# ------------------------------\n",
    "beta_cols = [col for col in df.columns if col.upper() != \"DATE\"]\n",
    "print(f\"Total Stocks: {len(beta_cols)}\")\n",
    "\n",
    "beta_values = df[beta_cols].to_numpy(dtype=np.float64)\n",
    "col_indices = np.arange(len(beta_cols))\n",
    "\n",
    "# Generate combinations \n",
    "combos = np.array(list(combinations(col_indices, 4)))\n",
    "print(f\"Total 4-stock combinations: {len(combos)}\")\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Combo\", \"Beta_Sum\"])\n",
    "\n",
    "    for i in tqdm(range(beta_values.shape[0]), desc=\"Processing Rows\"):\n",
    "        row = beta_values[i]\n",
    "\n",
    "        #  Fast batch extraction of values for all combos\n",
    "        vals = row[combos]  \n",
    "\n",
    "        # Masks\n",
    "        all_nan = np.isnan(vals).all(axis=1)\n",
    "        valid_vals = vals[~all_nan]\n",
    "\n",
    "        beta_sums = np.nansum(valid_vals, axis=1)\n",
    "        valid_combos = combos[~all_nan]\n",
    "\n",
    "        for combo_idx, beta_sum in zip(valid_combos, beta_sums):\n",
    "            combo_name = \", \".join(beta_cols[j] for j in combo_idx)\n",
    "            writer.writerow([combo_name, beta_sum])\n",
    "\n",
    "print(\"CSV created successfully!\")\n",
    "print(\"File saved at:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01a8527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Beta dictionary built\n",
      " COMPLETED — ZERO MEMORY RISK\n"
     ]
    }
   ],
   "source": [
    "#Beta_Total_EURINR_NIFTY\n",
    "\n",
    "import csv\n",
    "\n",
    "beta_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\beta_total.csv\"\n",
    "data_file = r\"C:\\Users\\Swarupa\\Downloads\\Latest_day_Ratio_should_not_be_GT_1.03_times_50DMA.csv\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Beta_Sum_EURINR_NIFTY.csv\"\n",
    "\n",
    "def normalize_combo(combo):\n",
    "    if not combo:\n",
    "        return None\n",
    "    combo = combo.replace(\"_Beta\", \"\")\n",
    "    parts = [c.strip() for c in combo.split(\",\")]\n",
    "    parts.sort()\n",
    "    return \",\".join(parts)\n",
    "\n",
    "# -------- LOAD BETA INTO DICTIONARY ----------\n",
    "beta_dict = {}\n",
    "\n",
    "with open(beta_file, newline='', encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        clean = normalize_combo(row[\"Combo\"])\n",
    "        beta_dict[clean] = row[\"Beta_Sum\"]\n",
    "\n",
    "print(\" Beta dictionary built\")\n",
    "\n",
    "# -------- STREAM SECOND FILE ----------\n",
    "with open(data_file, newline='', encoding=\"utf-8\") as f_in, \\\n",
    "     open(output_file, \"w\", newline='', encoding=\"utf-8\") as f_out:\n",
    "\n",
    "    reader = csv.DictReader(f_in)\n",
    "    fieldnames = reader.fieldnames + [\"Beta_Sum\"]\n",
    "    writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        clean = normalize_combo(row[\"Combo\"])\n",
    "        beta = beta_dict.get(clean)\n",
    "\n",
    "        if beta is not None:\n",
    "            row[\"Beta_Sum\"] = beta\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\" COMPLETED \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9760e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged data file...\n",
      "Sorting by lowest Beta_Sum...\n",
      "Saving Top 10 lowest Beta_Sum combinations...\n",
      " Done! Top 10 Lowest Beta_Sum file created.\n"
     ]
    }
   ],
   "source": [
    "#Top10_Lowest_Beta_Total\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------- USER FILE PATHS --------\n",
    "input_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Beta_Sum_EURINR_NIFTY.csv\"\n",
    "output_file = r\"D:\\Trading Stratergies\\Stratergy 2 All Codes\\Top10_Lowest_Beta_Sum.xlsx\"\n",
    "\n",
    "print(\"Loading merged data file...\")\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(\"Sorting by lowest Beta_Sum...\")\n",
    "\n",
    "# Sort ascending = lowest Beta_Sum first\n",
    "df_sorted = df.sort_values(by=\"Beta_Sum\", ascending=True)\n",
    "\n",
    "# Select top 10 lowest Beta_Sum combos\n",
    "top10_lowest = df_sorted.head(10)\n",
    "\n",
    "print(\"Saving Top 10 lowest Beta_Sum combinations...\")\n",
    "top10_lowest.to_excel(output_file, index=False)\n",
    "\n",
    "print(\" Done! Top 10 Lowest Beta_Sum file created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ca2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
